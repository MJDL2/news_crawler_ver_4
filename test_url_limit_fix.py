"""
URL ìˆ˜ì§‘ ì œí•œ ë¡œì§ ìˆ˜ì • í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
sys.path.append('src')

from datetime import datetime
from src.core.daily_collector import NaverNewsDailyCollector

def test_daily_limit_fix():
    """ì¼ë³„ ìˆ˜ì§‘ ì œí•œ ìˆ˜ì • í…ŒìŠ¤íŠ¸"""
    print("=== URL ìˆ˜ì§‘ ì œí•œ ë¡œì§ ìˆ˜ì • í…ŒìŠ¤íŠ¸ ===")
    
    collector = NaverNewsDailyCollector()
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    query = "ì›ì „"
    test_date = datetime(2025, 5, 29)
    daily_limit = 15  # 15ê°œë¡œ ì„¤ì •
    
    print(f"ê²€ìƒ‰ì–´: {query}")  
    print(f"ë‚ ì§œ: {test_date.strftime('%Y-%m-%d')}")
    print(f"ì¼ë³„ ì œí•œ: {daily_limit}ê°œ")
    print(f"ê¸°ëŒ€ ê²°ê³¼: {daily_limit}ê°œ ìˆ˜ì§‘ (ë˜ëŠ” í•´ë‹¹ ë‚ ì§œì˜ ìµœëŒ€ ê°€ëŠ¥ ê°œìˆ˜)")
    print()
    
    # ë‹¨ì¼ ë‚ ì§œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
    result = collector.collect_single_day(
        query=query,
        date=test_date,
        sort='recent',
        news_type='all',
        extract_content=True,
        daily_limit=daily_limit,
        save_intermediate=False
    )
    
    print(f"\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
    print(f"ìˆ˜ì§‘ëœ URL: {result.get('urls_collected', 0)}ê°œ")
    print(f"ì¶”ì¶œëœ ë³¸ë¬¸: {result.get('contents_extracted', 0)}ê°œ")
    print(f"ìƒíƒœ: {result.get('status', 'unknown')}")
    
    # ê²°ê³¼ ë¶„ì„
    urls_collected = result.get('urls_collected', 0)
    if urls_collected == daily_limit:
        print(f"ğŸ‰ ì„±ê³µ: ì •í™•íˆ {daily_limit}ê°œ ìˆ˜ì§‘ë¨")
    elif urls_collected > 8:  # ê¸°ì¡´ 8ê°œ ì œí•œì„ ë„˜ì–´ì„°ë‹¤ë©´ ê°œì„ ë¨
        print(f"âœ… ê°œì„ ë¨: {urls_collected}ê°œ ìˆ˜ì§‘ (ê¸°ì¡´ 8ê°œ â†’ {urls_collected}ê°œ)")
    elif urls_collected == 8:
        print(f"âŒ ì—¬ì „íˆ 8ê°œ ì œí•œ: ì¶”ê°€ í™•ì¸ í•„ìš”")
    else:
        print(f"âš ï¸  ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²°ê³¼: {urls_collected}ê°œ")
    
    return result

if __name__ == "__main__":
    result = test_daily_limit_fix()
